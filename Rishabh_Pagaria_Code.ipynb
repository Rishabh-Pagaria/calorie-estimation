{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Note: All debugging, output and plotting statements have been commented out for the ease of the reader. Please uncomment whatever output/plot is to be analyzed.\n"
      ],
      "metadata": {
        "id": "DVlwifGQPurK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "IlvQ2q0nod9M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o3901lymoN3i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import numpy as np\n",
        "from matplotlib_venn import venn2\n",
        "import ast\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from PIL import Image\n",
        "import io\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, LSTM, Dense, Concatenate, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        ")\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Data Loading"
      ],
      "metadata": {
        "id": "h5PRsPHnoc_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_train = pd.read_csv('img_train.csv')\n",
        "image_test = pd.read_csv('img_test.csv')\n",
        "demo_train = pd.read_csv('demo_viome_train.csv')\n",
        "\n",
        "cgm_train = pd.read_csv('cgm_train.csv')\n",
        "cgm_test = pd.read_csv('cgm_test.csv')\n",
        "demo_test = pd.read_csv('demo_viome_test.csv')"
      ],
      "metadata": {
        "id": "Phy81TXGo4Gn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing - Demographic Data (Part a)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MehUYIZOIwCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "race_mapping = {\n",
        "    \"Hispanic/Latino\": 0,\n",
        "    \"White\": 1,\n",
        "    \"African American\": 2,\n",
        "}\n",
        "\n",
        "demo_train[\"Race\"] = demo_train[\"Race\"].map(race_mapping)\n",
        "demo_test[\"Race\"] = demo_test[\"Race\"].map(race_mapping)\n",
        "\n",
        "def calculate_average(viome_string):\n",
        "      numbers = [float(num) for num in viome_string.split(',')]\n",
        "      return sum(numbers) / len(numbers)\n",
        "\n",
        "demo_train['Viome'] = demo_train['Viome'].apply(calculate_average)"
      ],
      "metadata": {
        "id": "w3PIS6AiIwP2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing - Images (Part a)"
      ],
      "metadata": {
        "id": "idFEoTnvpdbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image_data(df, column_name, target_size=(64, 64, 3)):\n",
        "    def process_single_image(img_str):\n",
        "        try:\n",
        "            img = eval(img_str)\n",
        "            img_array = np.array(img)\n",
        "\n",
        "            if img_array.size == 0: #empty\n",
        "              return np.zeros(target_size)\n",
        "\n",
        "            if len(img_array.shape) == 3 and img_array.shape[2] == 3:\n",
        "                pil_img = Image.fromarray(img_array.astype('uint8'), 'RGB')\n",
        "            elif len(img_array.shape) == 2:\n",
        "                pil_img = Image.fromarray(img_array.astype('uint8'), 'L')\n",
        "            else:\n",
        "                pil_img = Image.fromarray(img_array.reshape(target_size[:2]).astype('uint8'), 'L')\n",
        "            pil_img = pil_img.resize(target_size[:2])\n",
        "\n",
        "            if pil_img.mode != 'RGB':\n",
        "                pil_img = pil_img.convert('RGB')\n",
        "\n",
        "            return np.array(pil_img).astype(float) / 255.0\n",
        "        except Exception as e:\n",
        "            #print(f\"Error processing image: {e}\")\n",
        "            return np.zeros(target_size)\n",
        "\n",
        "    processed_images = df[column_name].apply(process_single_image).values\n",
        "    final_array = np.array(list(processed_images))\n",
        "\n",
        "    return final_array\n",
        "\n",
        "# Preprocess breakfast and lunch images\n",
        "X_breakfast = preprocess_image_data(image_train, 'Image Before Breakfast')\n",
        "X_lunch = preprocess_image_data(image_train, 'Image Before Lunch')\n",
        "\n",
        "image_train['Image Before Breakfast'] = list(X_breakfast)\n",
        "image_train['Image Before Lunch'] = list(X_lunch)\n",
        "# print(\"X_breakfast shape:\", X_breakfast.shape)\n",
        "# print(\"X_lunch shape:\", X_lunch.shape)\n"
      ],
      "metadata": {
        "id": "BnD5rAdYpf_y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Prediction Label (Part a)"
      ],
      "metadata": {
        "id": "hHKeI-H7p-N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_train = pd.read_csv('label_train.csv')\n",
        "y = label_train['Lunch Calories'].values"
      ],
      "metadata": {
        "id": "44YqK1M_qBEY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Time Series Label (Part a)"
      ],
      "metadata": {
        "id": "44eo27H8tEo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(cgm_train)\n",
        "\n",
        "def preprocess_row(row): #skipping normalization on this since we did not see a need\n",
        "    try:\n",
        "        cgm_data = eval(row['CGM Data'])\n",
        "    except:\n",
        "        cgm_data = []\n",
        "\n",
        "    cgm_values = [value for _, value in cgm_data] if cgm_data else []\n",
        "\n",
        "    if cgm_values:\n",
        "      return cgm_values\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "df['processed_cgm'] = df.apply(preprocess_row, axis=1)\n",
        "\n",
        "X = df['processed_cgm'].tolist()\n",
        "\n",
        "X_cgm = pad_sequences(X, padding='post', dtype='float32')\n",
        "\n",
        "cgm_train['CGM Data'] = list(X_cgm)\n",
        "# print(\"X (padded) shape:\", X_cgm.shape)\n",
        "# print(\"First padded sequence:\", X_cgm[0])"
      ],
      "metadata": {
        "id": "_xQ22wxNtIRk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of Demographic Data Handling\n",
        "\n",
        "For why demographic data is not pre-processed, refer to the report.\n",
        "\n",
        "---\n",
        "\n",
        "#### Summary:\n",
        "\n",
        "1. The data in `label_train.csv` has the same lunch calories for each subject on a given day.\n",
        "   - For example, Subject ID 1 on Day 2 has the same lunch calories as Subject ID 2 on Day 2, and so on for different subject IDs on the same days.\n",
        "\n",
        "2. The demographic data does not include day-specific information. This creates two possibilities:\n",
        "   \n",
        "   a. **Averaging lunch calories across all days in `label_train.csv`:**  \n",
        "      - This would result in the same average lunch calories for all subjects, rendering the demographic data ineffective.\n",
        "\n",
        "   b. **Duplicating demographic data for each day:**  \n",
        "      - This would lead to identical demographic data being associated with varying outputs, potentially worsening the model's performance.\n"
      ],
      "metadata": {
        "id": "LRPutqTp7C6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Kaggle Loss Function (Part d)"
      ],
      "metadata": {
        "id": "44WjCXoV33p9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmsre(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    return tf.sqrt(tf.reduce_mean(tf.square((y_true - y_pred) / y_true)))\n",
        "\n",
        "def rmsre_torch(predictions, targets):\n",
        "    relative_errors = (predictions - targets) / targets\n",
        "    return torch.sqrt(torch.mean(relative_errors ** 2))\n"
      ],
      "metadata": {
        "id": "uXHWU3Hy3zhy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating DataLoader for all three modalities (Part b)"
      ],
      "metadata": {
        "id": "OEshIpniMCrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data = cgm_train.merge(image_train, on=['Subject ID', 'Day'])\n",
        "merged_with_demo = merged_data.merge(demo_train, on='Subject ID', how='left')\n",
        "train_labels = pd.read_csv(\"label_train.csv\")\n",
        "final_merged = merged_with_demo.merge(train_labels, on=['Subject ID', 'Day'])\n",
        "# print(final_merged)\n",
        "\n",
        "numeric_columns = final_merged.select_dtypes(include=['int64', 'float64']).columns\n",
        "final_merged[numeric_columns] = final_merged[numeric_columns].astype('float32')\n",
        "\n",
        "categorical_columns = ['Breakfast Time', 'Lunch Time', 'CGM Data', 'Image Before Breakfast', 'Image Before Lunch']\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "for col in categorical_columns:\n",
        "    if final_merged[col].dtype == 'object':\n",
        "        final_merged[col] = label_encoder.fit_transform(final_merged[col].astype(str))\n",
        "\n",
        "final_merged.fillna(0, inplace=True)\n",
        "\n",
        "# print(final_merged.dtypes)\n",
        "\n",
        "feature_columns = [col for col in final_merged.columns if col not in ['Subject ID', 'Day', 'Lunch Calories']]\n",
        "X = final_merged[feature_columns].values\n",
        "y = final_merged['Lunch Calories'].values\n",
        "\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "dza0Jo3DMJ5Z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding data together\n",
        "\n",
        "Includes : Data Preparation, Multimodal model implementation, Model Training using pytorch (Part c,d,e without hypertuning)"
      ],
      "metadata": {
        "id": "L9KT_Rfr14LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMEncoder(nn.Module):\n",
        "    def __init__(self, sequence_length, num_features):\n",
        "        super(LSTMEncoder, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=num_features, hidden_size=64, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        return torch.tanh(h_n.squeeze(0))\n",
        "\n",
        "class CNNEncoder(nn.Module):\n",
        "    def __init__(self, image_shape):\n",
        "        super(CNNEncoder, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=image_shape[2], out_channels=32, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "        flattened_size = self._get_flattened_size(image_shape)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(flattened_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "    def _get_flattened_size(self, shape):\n",
        "        with torch.no_grad():\n",
        "            x = torch.zeros(1, *shape).permute(0, 3, 1, 2)\n",
        "            x = self.cnn(x)\n",
        "            return x.numel()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        x = self.cnn(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class FusionModel(nn.Module):\n",
        "    def __init__(self, sequence_length, num_features, image_shape):\n",
        "        super(FusionModel, self).__init__()\n",
        "        self.lstm_encoder = LSTMEncoder(sequence_length, num_features)\n",
        "        self.cnn_breakfast_encoder = CNNEncoder(image_shape)\n",
        "        self.cnn_lunch_encoder = CNNEncoder(image_shape)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64 + 128 + 128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, cgm, breakfast, lunch):\n",
        "        lstm_out = self.lstm_encoder(cgm)\n",
        "        breakfast_out = self.cnn_breakfast_encoder(breakfast)\n",
        "        lunch_out = self.cnn_lunch_encoder(lunch)\n",
        "        fusion = torch.cat([lstm_out, breakfast_out, lunch_out], dim=1)\n",
        "        output = self.fc(fusion)\n",
        "        return output\n",
        "\n",
        "device = torch.device(\"cpu\") #can be changed\n",
        "model = FusionModel(sequence_length=98, num_features=1, image_shape=(64, 64, 3)).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "X_cgm = torch.tensor(X_cgm, dtype=torch.float32).unsqueeze(-1).to(device) #added dimension to make it consistent with other inputs\n",
        "X_breakfast = torch.tensor(X_breakfast, dtype=torch.float32).to(device)\n",
        "X_lunch = torch.tensor(X_lunch, dtype=torch.float32).to(device)\n",
        "y = torch.tensor(y, dtype=torch.float32).to(device)\n",
        "# print(X_cgm.shape)\n",
        "# print(X_breakfast.shape)\n",
        "# print(X_lunch.shape)\n",
        "\n",
        "dataset = torch.utils.data.TensorDataset(X_cgm, X_breakfast, X_lunch, y)\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch_cgm, batch_breakfast, batch_lunch, batch_y in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(batch_cgm, batch_breakfast, batch_lunch).squeeze()\n",
        "        loss = rmsre_torch(outputs, batch_y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    #print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss / len(data_loader):.4f}\") #debugger\n",
        "\n",
        "# Model summary equivalent\n",
        "# print(model)\n",
        "\n",
        "model.eval()\n",
        "X_test_breakfast = preprocess_image_data(image_test, 'Image Before Breakfast')\n",
        "\n",
        "df_test = pd.DataFrame(cgm_test)\n",
        "df_test['processed_cgm'] = df_test.apply(preprocess_row, axis=1)\n",
        "X_test_cgm = pad_sequences(df_test['processed_cgm'].tolist(), padding='post', dtype='float32')\n",
        "\n",
        "X_test_lunch = preprocess_image_data(image_test, 'Image Before Lunch')\n",
        "X_test_cgm = torch.tensor(X_test_cgm, dtype=torch.float32).unsqueeze(-1).to(device)\n",
        "X_test_breakfast = torch.tensor(X_test_breakfast, dtype=torch.float32).to(device)\n",
        "X_test_lunch = torch.tensor(X_test_lunch, dtype=torch.float32).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_test_cgm, X_test_breakfast, X_test_lunch)\n",
        "\n",
        "predictions_np = predictions.cpu().numpy()\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    'row_id': np.arange(len(predictions_np)),\n",
        "    'label': predictions_np.flatten()\n",
        "})\n",
        "\n",
        "submission_df.to_csv('submission_torch_notuning.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "XnW9g0dTUYco",
        "outputId": "0b0b736f-1ce7-4196-9c9f-4f596f9fbe6d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-3e552255d53d>\u001b[0m in \u001b[0;36m<cell line: 83>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_cgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_breakfast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_lunch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrmsre_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-3e552255d53d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, cgm, breakfast, lunch)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbreakfast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlunch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcgm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mbreakfast_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_breakfast_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbreakfast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mlunch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_lunch_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlunch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-3e552255d53d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m             result = _VF.lstm(\n\u001b[0m\u001b[1;32m   1124\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m                 \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperameter Tuning (Part e)\n",
        "\n",
        "Note: We designed a pytorch model as was required for part c but for hyperparameter tuning we have implemented the equivalent model in tensorflow since that is what we were more comfortable with.\n",
        "Hyperparameter tuning involved dynamic size calculation and we were able to do it easier on tensorflow"
      ],
      "metadata": {
        "id": "4pRzcDCXxJBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams = {\n",
        "    'lstm_units': [64, 128],\n",
        "    'cnn_filters': [64, 96],\n",
        "    'dense_units': [128, 256],\n",
        "    'learning_rate': [0.001],\n",
        "    'dropout_rate': [0.3, 0.5]\n",
        "}\n",
        "\n",
        "def create_model(lstm_units, cnn_filters, dense_units, learning_rate, dropout_rate):\n",
        "    sequence_length = 98 #cgm sequences were padded to 98 earlier\n",
        "    num_features = 1\n",
        "    image_shape = (64, 64, 3)\n",
        "\n",
        "    lstm_input = Input(shape=(sequence_length, num_features))\n",
        "    lstm_out = LSTM(lstm_units, activation=\"tanh\")(lstm_input)\n",
        "\n",
        "    cnn_breakfast_input = Input(shape=image_shape)\n",
        "    x = Conv2D(cnn_filters, (3, 3), activation=\"relu\")(cnn_breakfast_input)\n",
        "    x = MaxPooling2D((2, 2), name=\"breakfast_pool1\")(x)\n",
        "    x = Conv2D(cnn_filters*2, (3, 3), activation=\"relu\")(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(dense_units, activation=\"relu\")(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    cnn_lunch_input = Input(shape=image_shape)\n",
        "    x2 = Conv2D(cnn_filters, (3, 3), activation=\"relu\")(cnn_lunch_input)\n",
        "    x2 = MaxPooling2D((2, 2))(x2)\n",
        "    x2 = Conv2D(cnn_filters*2, (3, 3), activation=\"relu\")(x2)\n",
        "    x2 = MaxPooling2D((2, 2))(x2)\n",
        "    x2 = Flatten()(x2)\n",
        "    x2 = Dense(dense_units, activation=\"relu\")(x2)\n",
        "    x2 = Dropout(dropout_rate)(x2)\n",
        "\n",
        "    fusion = Concatenate()([lstm_out, x, x2])\n",
        "\n",
        "    fc = Dense(dense_units, activation=\"relu\")(fusion)\n",
        "    fc = Dropout(dropout_rate)(fc)\n",
        "    fc = Dense(dense_units//2, activation=\"relu\")(fc)\n",
        "    output = Dense(1, activation=\"linear\")(fc)\n",
        "\n",
        "    model = Model(inputs=[lstm_input, cnn_breakfast_input, cnn_lunch_input], outputs=output)\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss=rmsre, metrics=[rmsre])\n",
        "\n",
        "    return model\n",
        "\n",
        "best_model = None\n",
        "best_history = None\n",
        "best_score = float('inf')\n",
        "best_params = None\n",
        "\n",
        "for lstm_units in hyperparams['lstm_units']:\n",
        "    for cnn_filters in hyperparams['cnn_filters']:\n",
        "        for dense_units in hyperparams['dense_units']:\n",
        "            for lr in hyperparams['learning_rate']:\n",
        "                for dropout in hyperparams['dropout_rate']:\n",
        "                    #print(f\"\\nTesting parameters: LSTM={lstm_units}, CNN={cnn_filters}, Dense={dense_units}, LR={lr}, Dropout={dropout}\")\n",
        "\n",
        "                    model = create_model(lstm_units, cnn_filters, dense_units, lr, dropout)\n",
        "\n",
        "                    history = model.fit(\n",
        "                        [X_cgm, X_breakfast, X_lunch],\n",
        "                        y,\n",
        "                        epochs=5,\n",
        "                        batch_size=32,\n",
        "                        verbose=1\n",
        "                    )\n",
        "\n",
        "                    train_loss = min(history.history['loss'])\n",
        "                    if train_loss < best_score:\n",
        "                        best_score = train_loss\n",
        "                        best_params = {\n",
        "                            'lstm_units': lstm_units,\n",
        "                            'cnn_filters': cnn_filters,\n",
        "                            'dense_units': dense_units,\n",
        "                            'learning_rate': lr,\n",
        "                            'dropout_rate': dropout\n",
        "                        }\n",
        "                        best_history = history\n",
        "                        best_model = model\n",
        "\n",
        "#print(\"\\nBest parameters found:\")\n",
        "# for param, value in best_params.items():\n",
        "#     #print(f\"{param}: {value}\")\n",
        "# print(f\"Best training loss: {best_score}\")\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.plot(best_history.history['loss'], label='Training Loss')\n",
        "# plt.title('Loss vs Epochs for Best Model')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "BHFfyuWaxIWm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "f7eb957a-cca8-4c86-c20c-70683291fc8a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m 7/11\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.9869 - rmsre: 0.9869"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-10fdcc058ee5>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                     history = model.fit(\n\u001b[0m\u001b[1;32m     64\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mX_cgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_breakfast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_lunch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing test data similiar to the training data and Making Predictions"
      ],
      "metadata": {
        "id": "f5sS8YX95Mvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test_breakfast = preprocess_image_data(image_test, 'Image Before Breakfast')\n",
        "\n",
        "df_test = pd.DataFrame(cgm_test)\n",
        "df_test['processed_cgm'] = df_test.apply(preprocess_row, axis=1)\n",
        "X_test_cgm = pad_sequences(df_test['processed_cgm'].tolist(), padding='post', dtype='float32')\n",
        "\n",
        "X_test_lunch = preprocess_image_data(image_test, 'Image Before Lunch')\n",
        "\n",
        "predictions = best_model.predict([X_test_cgm, X_test_breakfast, X_test_lunch])\n",
        "predictions = predictions.flatten()"
      ],
      "metadata": {
        "id": "WfUuMGsj5O87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making appropriate csv to submit to Kaggle"
      ],
      "metadata": {
        "id": "dZ31UuRY5Ybd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame({\n",
        "    'row_id': np.arange(len(predictions)),\n",
        "    'label': predictions\n",
        "})\n",
        "\n",
        "submission_df.to_csv('submission_tensorflow_tuning.csv', index=False)"
      ],
      "metadata": {
        "id": "VZoGihnz5eJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: We removed splitting the data to validation data for the final run to make use of the full training dataset for submitting to Kaggle. While designing and picking the best models, etc. we did use validation"
      ],
      "metadata": {
        "id": "hrwcXeQjl2UT"
      }
    }
  ]
}